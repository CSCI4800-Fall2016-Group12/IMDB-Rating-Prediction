{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chris Padgett\n",
    "\n",
    "Greg Peters\n",
    "\n",
    "CSCI 4800 Data Science\n",
    "\n",
    "# IMDB Data Collection\n",
    "\n",
    "This notebook serves as a collection of the commands used to collect and organize data scraped from the International Movie Database (IMDB). Since collection of data is not the focus of the project we will be utilizing some code from a [similar project](https://blog.nycdatascience.com/student-works/machine-learning/movie-rating-prediction/) as a starting point for our data collection.\n",
    "\n",
    "The data will be collected using the python package [Scrapy](https://scrapy.org/) which must be installed to run the code. Since we will need to collect data from multiple website urls, the data collection will be done in small steps saving the data to disk at every step. The python code used to collect the data uses a typical Scrapy project layout. This code is located in the \"movie\" directory.\n",
    "\n",
    "In order to get the data that is relevant to our project we will need to query a few urls in different steps. During these steps we will be saving other movie data even though our project might not use it. This is to allow us to incorporate different data in the case we feel it can improve our ratings predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Important Notes\n",
    "\n",
    "When running the following steps there are a couple important notes to consider:\n",
    "* This notebook is supplied with data that has already been collected. When collecting new data the code will append the scraped data to the json data files. This results in an invalid json object file, the previous file data will need to be removed. This is made easier by creating an empty json file and deleting the empty json object after collecting the data.\n",
    "* Scrapy produces a lot of output and we use 5,000+ movies so it is not advised to run Scrapy within this notebook. As such, all shell commands will not be in code cells.\n",
    "* All commands should be ran in the \"Data Collection\" directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create Movie List\n",
    "\n",
    "Use the-numbers.com to create a list of movie titles. The budget data from the site will also be collected. The data will be saved in the file \"movie_budget.json\".\n",
    "\n",
    "### Scrapy shell command\n",
    "\n",
    "> scrapy crawl movie_budget -o movie_budget.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Step 2: Get IMDB Movie URLs\n",
    "\n",
    "Use the IMDB search feature to get the IMDB URL paths for each movie.\n",
    "\n",
    "### Scrapy shell command\n",
    "\n",
    "> scrapy crawl fetch_imdb_url -o fetch_imdb_url.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Get IMDB General Movie Data\n",
    "\n",
    "Gather all of the data from imdb.com except for the cast and writers.\n",
    "\n",
    "### Scrapy shell command\n",
    "\n",
    "> scrapy crawl imdb -o imdb_output.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Get IMDB Cast and Writer Movie Data\n",
    "\n",
    "Gather the full cast and writer data from imdb.com.\n",
    "\n",
    "### Scrapy shell command\n",
    "\n",
    "> scrapy crawl imdb_people -o imdb_people.json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
